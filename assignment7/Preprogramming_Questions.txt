{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf470
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww12040\viewh8000\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \ul \ulc0 Preprogramming Questions.\ulnone \
\
1. What action is assigned in the terminal state?\
\
	
\b A: \'93return None\'94, we assign NO action to a terminal state.\
\

\b0 2. Where are the transition probabilities defined in the program, and what are those probabilities?\
\
	
\b A: Defined in class GridMDP, function T (which also transition to class MDP, function T).\
	    The probabilities are: 0.8 (success), 0.1 (left), 0.1 (right).\
\

\b0 3. What function needs to be called to run value iteration?\
\
	
\b A: There are several functions within the class that need to be run. \
	    They are: function R, function T, function actions, \
	    and also several functions in the utils.py class (add_vector, left_action, right_action, ect.). \
\
	    There are also several variable that need to be set to run (mdp.states, map.gamma, ect.).\
\

\b0 4. When you run value iteration on the MDP provided, the results are stored in a variable called myMDP. What is utility of (0,1), (3,1), and (2,2).\
\
	
\b A: Printing the utilities gives (this gridWorld is the small one provided - not horse grid):\
	    (0,1) : 0.3984432178350045\
	    (3,1) : -1.0\
	    (2,2) : 0.795362087846678\
\

\b0 5. How are actions represented, and what are the possible actions for each state in the program?\
\
	
\b A: Actions are represented as a <x,y> (or (x,y)) vector. Possible actions are:\
	   (1,0) : east (right)\
	   (-1,0) : west (left)\
	   (0,1) : north (up)\
	   (0,-1) : south (down)\
	   None : terminal state - no action\

\b0 \

\b \

\b0 \
}